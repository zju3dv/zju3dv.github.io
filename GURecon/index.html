<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
          content="GURecon: Learning Detailed 3D Geometric Uncertainties for Neural Surface Reconstruction">
    <meta name="keywords" content="nerf,neus,uncertainty,geometry,GURecon">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>GURecon: Learning Detailed 3D Geometric Uncertainties for Neural Surface Reconstruction</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css"><!-- 提供响应式布局 -->
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css"><!-- 用于图像和视频的轮播 -->
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css"><!-- 用于图标展示 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <!-- 提供与学术相关的图标 -->
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="static/css/style.css">


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <script src="static/js/video_comparison.js"></script>
    <script src="static/js/app.js"></script>
    <link rel="stylesheet" href="static/css/dics.original.css">
    <script src="static/js/event_handler.js"></script>
    <script src="static/js/dics.original.js"></script>
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <link rel="stylesheet" href="static/css/bootstrap-4.4.1.css">
    <!--script type="module" src="static/js/model-viewer.min.js"></script-->

    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>


    <style>
        .video-margin {
            margin-bottom: 20px;
        }
    </style>
    <style>
        .reduce-space {
            margin-bottom: -100px;
        }
    </style>

</head>

<body>
<section class="hero">
    <div class="reduce-space">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered"> <!---->
                    <div class="column has-text-centered"><!---->
                        <h1 class="title is-1 publication-title">GURecon: Learning Detailed 3D Geometric
                            Uncertainties for Neural Surface Reconstruction</h1>
                        <h1 class="title is-size-3" style="color:#5a6268;">AAAI 2025 Oral</h1>

                        <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    [<a href="https://github.com/YZsZY">Zesong Yang</a><sup>1</sup>,
                                </span>
                            <span class="author-block">
                                    <a href="https://github.com/zrrr333/">Ru Zhang</a><sup>1</sup>,
                                </span>
                            <span class="author-block">
                                    <a href="https://github.com/shijialew">Jiale
                                        Shi</a><sup>1</sup>]<sup>Co-Authors</sup>,
                                </span>
                            <span class="author-block">
                                    <a href="https://zhoujiahuan1991.github.io/student_pages/azxEN.html">Zixiang
                                        Ai</a><sup>1</sup>,
                                </span>
                            <span class="author-block">
                                    <a href="https://bomingzhao.github.io/">Boming Zhao</a><sup>1</sup>,
                                </span>
                            <br>
                            <span class="author-block">
                                    <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a><sup>1</sup>,
                                </span>
                            <span class="author-block">Luwei Yang</a><sup>2</sup>,</span>
                            <span class="author-block">
                                    <a href="https://zhpcui.github.io/">Zhaopeng Cui†</a><sup>1</sup>,
                                </span>
                        </div>
                        <div class="is-size-5 publication-authors">
                                <span class="author-block"><sup>1</sup>State Key Lab of CAD & CG, Zhejiang
                                    University,</span>
                            <span class="author-block"><sup>2</sup>Simon Fraser University</span>
                            <br>
                            <span class="author-block"><sup>†</sup>Corresponding Authors</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                    <span class="link-block">
                                        <a href="sources/aaai25_gurecon.pdf"
                                           class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fas fa-file-pdf"></i>
                                            </span>
                                            <span>Paper</span>
                                        </a>
                                    </span>


                                <span class="link-block"><!-- Arixv -->
                                        <a href="https://arxiv.org/abs/2412.14939"
                                           class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="ai ai-arxiv"></i>
                                            </span>
                                            <span>ArXiv</span>
                                        </a>
                                    </span>

                                <span class="link-block">
                                        <a href="sources/supp.pdf"
                                           class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fas fa-file-pdf"></i>
                                            </span>
                                            <span>Supplementary</span>
                                        </a>
                                    </span>

                                <span class="link-block">
                                        <a href="https://github.com/zju3dv/GURecon"
                                           class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fab fa-github"></i>
                                            </span>
                                            <span>Code</span>
                                        </a>
                                    </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Abstract -->>
<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="rows is-centered">
            <figure>
                <video id="r10k" autoplay muted loop playsinline width="100%">
                    <source src="sources/video/teaser.mp4" type="video/mp4">
                </video>
                <!-- <figcaption class="tagline">
          GVGEN possesses a fast generation speed <b>(~7 seconds)</b>, effectively striking a balance between quality and efficiency.
        </figcaption> -->
            </figure>

            <h2 class="title is-3 has-text-centered">Abstract</h2>
            <div class="content has-text-justified">
                Neural surface representation has demonstrated remarkable success in the areas of novel view
                synthesis and 3D reconstruction.
                However, assessing the geometric quality of 3D reconstructions in the absence of ground truth mesh
                remains a significant challenge,
                due to its rendering-based optimization process and entangled learning of appearance and geometry
                with photometric losses.
                In this paper, we present a novel framework, i.e, <b>GURecon</b>, which establishes a geometric
                uncertainty field for the neural surface based on geometric consistency.
                Different from existing methods that rely on rendering-based measurement,
                <b>GURecon</b> models a continuous 3D uncertainty field for the reconstructed surface,
                and is learned by an online distillation approach without introducing real geometric information for
                supervision.
                Moreover, in order to mitigate the interference of illumination on geometric consistency,
                a decoupled field is learned and exploited to finetune the uncertainty field. Experiments on various
                datasets
                demonstrate the superiority of <b>GURecon</b> in modeling 3D geometric uncertainty,
                as well as its plug-and-play extension to various neural surface representations and improvement on
                downstream tasks such as incremental reconstruction.
            </div>


            <div style="text-align: center;"><img src="sources/images/pipeline.png" alt="pipeline" width="100%">
            </div>
            <p><strong>Fig. 1: System Overview.</strong>
                The proposed GURecon models a geometric uncertainty field supervised by the pseudo labels computed
                based on the multi-view geometry consistency.
                To deal with the view-dependent factors, additional decoupled fields are also learned and exploited
                to fine-tune the uncertainty field.
                With the predicted uncertainty fields, GURecon can boost the downstream tasks such as incremental
                reconstruction.</p>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <h2 class="title is-3">Comparison</h2>
        </div>

        <div class="content has-text-justified">
            Here, we present the reconstruction results and the corresponding geometric uncertainty predicted by
            <a href="https://bayesrays.github.io/" style="color: #3498db;">Bayes' Rays</a>
            and Ours.
        </div>
        <br>
        <div class="row">
            <div class="container is-max-desktop">
                <div class="container">
                    <!-- 创建一个无序列表 nav:导航菜单； -->
                    <!--
                    <ul class="nav nav-tabs nav-fill nav-justified" id="object-scale-recon">
                        <li class="nav-item">
                            <a class="nav-link" onclick="objectSceneEvent(0)">Barn</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" onclick="objectSceneEvent(1)">Caterpillar</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" onclick="objectSceneEvent(2)">Truck</a>
                        </li>
                    </ul>
                -->

                    <ul class="navigation">
                        <li onclick="objectSceneEvent(0)"><img src="sources/images/compare/Barn.jpeg" height="90px"
                                                               width="160px"></li>
                        <li onclick="objectSceneEvent(1)"><img src="sources/images/compare/Caterpillar.jpeg"
                                                               height="90px" width="160px"></li>
                        <li onclick="objectSceneEvent(2)"><img src="sources/images/compare/Truck.jpeg" height="90px"
                                                               width="160px"></li>
                    </ul>


                    <div class="b-dics" style="width: 1920px; font-weight: 1080;">
                        <img src="sources/images/compare/Barn/gt_normal.gif" alt="GT Normal">
                        <!--style="max-width: 100%; height: auto;"-->
                        <img src="sources/images/compare/Barn/pred_normal.gif" alt="Pred Normal">
                        <!--style="max-width: 100%; height: auto;"-->
                        <img src="sources/images/compare/Barn/gt_unc.gif" alt="GT Unc">
                        <!--style="max-width: 100%; height: auto;"-->
                        <img src="sources/images/compare/Barn/bayes_unc.gif" alt="Bayes' Rays">
                        <!--style="max-width: 100%; height: auto;"-->
                        <img src="sources/images/compare/Barn/ours_unc.gif" alt="Ours">
                        <!--style="max-width: 100%; height: auto;"-->
                    </div>

                </div>
            </div>
        </div>

        <!--
        <br>
        <div class="content has-text-justified">
            We show the interactive reconstructed mesh and our estimated geometric uncertainty.
        </div>
        <div class="model-container">
            <div class="column">
                <model-viewer alt="Mesh"
                    src="/Users/bytedance/Downloads/mesh/barn/mesh.obj"
                    style="width: 100%; height: 100%" exposure=".3" auto-rotate camera-controls
                    ar-status="not-presenting"></model-viewer>
            </div>
            <div class="column">
                <model-viewer alt="Mesh"
                    src="/Users/bytedance/Downloads/mesh/barn/pred.obj"
                    style="width: 100%; height: 100%" exposure=".8" auto-rotate camera-controls
                    ar-status="not-presenting"></model-viewer>
            </div>
        </div>
        -->
        <!--
        <br>
        <div class="content has-text-justified">
            Additionally, we also present comparisons with current mainstream neural-representation-based
            uncertainty estimation methods,
            including
            <a href="https://poetrywanderer.github.io/CF-NeRF/" style="color: #3498db;">CFNeRF</a> (variational
            inference),
            <a href="https://xuranpan.plus/publication/activenerf/" style="color: #3498db;">ActiveNeRF</a> (gaussian
            distributions),
            <a href="https://bayesrays.github.io/" style="color: #3498db;">Bayes' Rays</a> (laplacian
            approximation),
            and
            <a href="https://arxiv.org/abs/2209.08409" style="color: #3498db;">UncertaintyNeRF</a> (weight entropy).
        </div>
        <div style="text-align: center;">
            <img src="sources/images/compare.png" alt="compare" width="100%">
        </div>
    -->

    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="content has-text-justified">
            We show the interactive reconstructed mesh and our estimated geometric uncertainty. Please wait for the
            model to load.
        </div>
        <div class="columns">
            <div class="column">
                <model-viewer id="model-viewer-mesh" alt="Mesh"
                              src="https://raw.githubusercontent.com/zju3dv/GURecon/main/assets/meshes/Barn/mesh.glb"
                              style="width: 100%; height: 100%" exposure=".3" auto-rotate camera-controls
                              ar-status="not-presenting"></model-viewer>
            </div>
            <div class="column">
                <model-viewer id="model-viewer-uc" alt="Mesh"
                              src="https://raw.githubusercontent.com/zju3dv/GURecon/main/assets/meshes/Barn/colored_mesh.glb"
                              style="width: 100%; height: 100%" exposure=".3" auto-rotate camera-controls
                              ar-status="not-presenting"></model-viewer>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <h2 class="title is-3">Application: Incremental Reconstruction</h2>
        </div>

        <div class="content has-text-justified">
            We apply our geometric uncertainty to the incremental reconstruction task and
            compare with current mainstream NeRF-based incremental reconstruction methods:
            <a href="https://xuranpan.plus/publication/activenerf/" style="color: #3498db;">ActiveNeRF</a> (gaussian
            distributions) and <a href="https://arxiv.org/abs/2209.08409"
                                  style="color: #3498db;">UncertaintyNeRF</a> (weight entropy).
            Uncertainty dynamically reflects the current quality of the reconstruction.
        </div>

        <figure>
            <video id="r10k" autoplay muted loop playsinline width="100%">
                <source src="sources/video/increrecon.mp4" type="video/mp4">
            </video>
        </figure>

        <div class="content has-text-justified">
            Uncertainty dynamically reflects the current quality of the reconstruction.
        </div>

        <div style="text-align: center;">
            <img src="sources/images/incre_compare.png" alt="incre_compare" width="100%">
        </div>
    </div>
</section>


<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@inproceedings{yang2024gurecon,
    title     = {GURecon: Learning Detailed 3D Geometric Uncertainties for Neural Surface Reconstruction},
    author    = {Yang, Zesong and Zhang, Ru and Shi, Jiale and Ai, Zixiang and Zhao, Boming and Bao, Hujun and Yang, Luwei and Cui, Zhaopeng},
    booktitle = {AAAI},
    year      = {2025}
  }</code></pre>
    </div>
</section>


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <!-- <div class="column is-8"> -->
            <div class="content has-text-centered">
                <p>
                    This website page is sourced from <a href="https://github.com/nerfies/nerfies.github.io"
                                                         style="color: #3498db;">Nerfies</a> and
                    <a href="https://pixelgs.github.io/" style="color: #3498db;">PixelGS</a>.
                </p>
                <!-- </div> -->
            </div>
        </div>
    </div>
</footer>

</body>


</html>