<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- 不知道这里是干嘛的，还没改? -->
  <meta name="description"
        content="NeuMesh encodes the neural implicit field with disentangled geometry and texture features on a mesh scaffold, thereby enables mesh-guided geometry deformation, texture swapping, filling and painting.">
  <meta name="keywords" content="NeuMesh, Neural Rendering, Scene Editing, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:image" content="./static/images/thumbnail.png"/>
  <!--这里是链接图表的icon-->
  <link rel="icon"
        type="image/x-icon"
        href="./static/images/sun.png"/>

  <title>Neural Implicit Semantic RGB-D SLAM for 3D Consistent Scene Understanding
    </title>


  </script>

  <!-- <script type="module"
          src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-migrate-1.2.1.min.js"></script>
  <!-- <script src="https://unpkg.com/interactjs/dist/interact.min.js"></script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" type="text/css" href="./static/slick/slick.css"/>
  <link rel="stylesheet" type="text/css" href="./static/slick/slick-theme.css"/>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/zju3dv/Vox-Surf"> Vox-Surf</a>
          <a class="navbar-item" href="https://github.com/zju3dv/Vox-Fusion"> Vox-Fusion</a>
          <a class="navbar-item" href="https://zju3dv.github.io/splatloc/"> SplatLoc</a>
          <a class="navbar-item" href="https://zju3dv.github.io/neuraloc/"> NeuraLoc</a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-9 has-text-centered">
          <img style="width: 200%; transform: translate(0%, 0%);" src="./static/images/NIS-SLAM.png" alt="NIS-SLAM"/>
        </div>
      </div>
      <div class="container has-text-centered">
        <h1 class="title is-1 publication-title">
          Neural Implicit Semantic RGB-D SLAM for 3D Consistent Scene Understanding
        </h1>
        <h1 class="title is-size-3" style="color:#5a6268;">TVCG 2024 (ISMAR Journal Track)</h1>
        <div class="is-size-5 publication-authors">
          <div class="author-block">
            <a href="https://scholar.google.com/citations?user=alXpF8wAAAAJ&hl=en">Hongjia Zhai</a>,</div>
          <div class="author-block">
            <a href="https://github.com/huanggan52">Gan Huang</a>,</div>
          <div class="author-block">
            <a href="https://github.com/QiruiH">Qirui Hu</a>,</div>
            <div class="author-block">
            <a href="https://github.com/liguanglin">Guanglin Li</a>,</div>
          <div class="author-block">
            <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>,
          </div>
          <div class="author-block">
            <a href="http://www.cad.zju.edu.cn/home/gfzhang/">Guofeng Zhang</a>
          </div>
        </div>

        <div class="is-size-5 publication-authors">
          <!-- * denotes equal contribution <br> -->
          <span class="author-block">State Key Lab of CAD & CG, Zhejiang University</span>
        </div>

        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <span class="link-block">
                <a href="https://arxiv.org/abs/2407.20853"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
            <span class="link-block">
                <a href="https://arxiv.org/abs/2407.20853"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">

      <img style="width: 100%;" src="./static/images/teaser.jpg"
             alt="NIS-SLAM architecture."/>
      <div class="content has-text-justified">
        <p>
        <i>NIS-SLAM</i>, a neural implicit semantic RGB-D SLAM system that incrementally reconstructs the environment with 3D
        consistent scene understanding. As shown in the figure, taking continuous RGB-D frames and 2D noise segmentation results as input,
        our system can reconstruct high-fidelity surface and geometry, learn 3D consistent semantic field and recover the objects in the scene.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-fifth-sixths">
        <h2 class="title is-3" style="color:#ff9c7b;">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In recent years, the paradigm of neural implicit representations has gained substantial attention in the field of 
            Simultaneous Localization and Mapping (SLAM). However, a notable gap exists in the existing approaches when it 
            comes to scene understanding. In this paper, we introduce NIS-SLAM, an efficient neural semantic RGB-D SLAM system, 
            that leverages a pre-trained 2D segmentation network to learn consistent semantic representations. 
            Specifically, we use high-frequency multi-resolution tetrahedron-based features and low-frequency positional encoding 
            to perform scene reconstruction and understanding. The combination ensures both memory efficiency and spatial consistency. 
            Besides, to address the inconsistency of 2D segmentation results from multiple views, we propose a fusion strategy that 
            integrates the semantic probabilities from previous non-keyframes into keyframes to achieve consistent semantic learning. 
            Furthermore, we implement a confidence-based pixel sampling and progressive optimization weight function for robust 
            camera tracking. Extensive experimental results on various datasets show the better or more competitive performance 
            of our system when compared to other existing neural dense implicit RGB-D SLAM approaches. Besides, we also show that
             our approach can be used in augmented reality applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<hr/>

<section>
  <hr/>
  <div class="container is-max-desktop">
   <div class="columns is-centered has-text-centered">
      <div class="column is-forth-fifths">
        <h2 class="title is-2">YouTube Video</h2>
        <div class="publication-video">
          <iframe width="640" height="480" src="https://www.youtube.com/embed/2PSUyCEDVzc?si=HYtD3ZlvCR-eCWrA"
                  title="YouTube video player" frameborder="0"
                  allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
<!-- Framework Overview -->
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <h2 class="title is-3 has-text-centered" style="color:#ff9c7b;"><p>Framework Overview</p></h2>
      <div class="has-text-centered">
        <img style="width: 100%;" src="./static/images/slam_pipeline.png"
             alt="NIS-SLAM Overview."/>
      </div>
      <p>
        Our system takes RGB-D frames as input to perform camera tracking and mapping via volume rendering and 
        models 3D semantics with the noise 2D segmentation results from Mask2Former. 
        Based on the hybrid implicit representation of multi-resolution tetrahedron feature $\theta$ and positional encoding $\texttt{PE}(p)$, 
        we decode the SDF $\sigma$, latent feature $h$, color $c$, and semantic probability $s$ with three MLPs {$\mathcal{M}_{geo}$, 
        $\mathcal{M}_{color}$, and $\mathcal{M}_{sem}$}. To model consistent semantic property, we fuse multi-view semantics of nearby 
        non-keyframes for learning 3D consistent representation.
      </p>
    </div>
  </div>


    <br/>

    <div class="container is-max-desktop">
    <div class="content has-text-justified">
    <h2 class="title is-3 has-text-centered" style="color:#ff9c7b;"><p>Dense Reconstruction</p></h2>
    <h3 class="title is-5 has-text-centered" style="color:#f55d26;"><p>Reconstruction Results on ScanNet</p></h3>
      <div class="has-text-centered">
        <img style="width: 100%;" src="./static/images/scannet_mesh_tmp.png" alt="Reconstruction Result."/>
      </div>
      <p>
        <strong><font size="4">Annotations:</font></strong> Compared to the baselines, our method can reconstruct more accurate detailed geometry and
        generate more complete, smoother mesh. 
      </p>
    
      <h3 class="title is-5 has-text-centered" style="color:#f55d26;"><p>Object Reconstruction of Replica</p></h3>
      <div class="has-text-centered">

        <img style="width: 100%;" src="./static/images/replica.png" alt="Reconstruction Result."/>
      </div>
      <p>
        <strong><font size="4">Annotations:</font></strong> We show some selected objects for comparison with vMAP.
      </p>
    </div>
    </div>

    <br/>

    <div class="container is-max-desktop">
    <div class="content has-text-justified">
    <h2 class="title is-3 has-text-centered" style="color:#ff9c7b;"><p>Semantic Segmentation</p></h2>
      <div class="has-text-centered">
        <img style="width: 100%;" src="./static/images/semantic.png"
        alt="semantic segmentation."/>
      </div>
      <p>
        <strong><font size="4">Annotations:</font></strong>Semantic Segmentation Results on Replica. We show the multi-view segmentation results of different approaches. The top, middle,
        and bottom parts show the segmentation results of Mask2Former, our approach without semantic fusion, and our approach with semantic
        fusion respectively. Comparing the segmentation results from different views, we can see that our method can learn more consistent semantic
        representation.
      </h2>
    </div>
    </div>

    <br/>
    <br/>



</section>

<hr/>

<section class="section" id="BibTeX">
  <div class="container content is-max-desktop">
    <h2 class="title">BibTeX</h2>
    <pre><code>@ARTICLE{nis_slam,
      author={Zhai, Hongjia and Huang, Gan and Hu, Qirui and Li, Guanglin and Bao, Hujun and Zhang, Guofeng},
      journal={IEEE Transactions on Visualization and Computer Graphics}, 
      title={{NIS-SLAM}: Neural Implicit Semantic {RGB-D} {SLAM} for {3D} Consistent Scene Understanding}, 
      year={2024},
      volume={30},
      number={11},
      pages={7129-7139},
}
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      Thanks to <a href="https://www.flaticon.com/" target="_blank">Flaticon</a> for providing beautiful icons.
      The website template is borrowed from <a href="https://hypernerf.github.io/" target="_blank">HyperNeRF</a>.
    </div>
  </div>
</footer>

<script>
  MathJax = {
    tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
  };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-F5RT7HMEN2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-F5RT7HMEN2');
</script>

<script type="text/javascript" src="./static/slick/slick.min.js"></script>
</body>
</html>
